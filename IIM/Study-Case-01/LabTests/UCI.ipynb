{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import datetime\n",
    "import wfdb\n",
    "\n",
    "import wfdb\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.signal import butter,filtfilt\n",
    "import pywt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_signals_ucihar(filename):\n",
    "    with open(filename, 'r') as fp:\n",
    "        data = fp.read().splitlines()\n",
    "        data = map(lambda x: x.rstrip().lstrip().split(), data)\n",
    "        data = [list(map(float, line)) for line in data]\n",
    "    return data\n",
    "\n",
    "def read_labels_ucihar(filename):        \n",
    "    with open(filename, 'r') as fp:\n",
    "        activities = fp.read().splitlines()\n",
    "        activities = list(map(int, activities))\n",
    "    return activities\n",
    "\n",
    "def load_ucihar_data(folder):\n",
    "    train_folder = folder + '\\\\train\\\\Inertial Signals\\\\'\n",
    "    test_folder = folder + '\\\\test\\\\Inertial Signals\\\\'\n",
    "    labelfile_train = folder + '\\\\train\\\\y_train.txt'\n",
    "    labelfile_test = folder + '\\\\test\\\\y_test.txt'\n",
    "    train_signals, test_signals = [], []\n",
    "    for input_file in os.listdir(train_folder):\n",
    "        signal = read_signals_ucihar(train_folder + input_file)\n",
    "        train_signals.append(signal)\n",
    "    train_signals = np.transpose(np.array(train_signals), (1, 2, 0))\n",
    "    for input_file in os.listdir(test_folder):\n",
    "        signal = read_signals_ucihar(test_folder + input_file)\n",
    "        test_signals.append(signal)\n",
    "    test_signals = np.transpose(np.array(test_signals), (1, 2, 0))\n",
    "    train_labels = read_labels_ucihar(labelfile_train)\n",
    "    test_labels = read_labels_ucihar(labelfile_test)\n",
    "    return train_signals, train_labels, test_signals, test_labels\n",
    "\n",
    "folder_ucihar = r'G:\\Meu Drive\\Pós-Graduação - Mestrado UFSC - Engenharia Eletrica\\Disciplinas\\Introdução á informatica médica\\trabalhos\\Estudo de caso 01\\UCI HAR Dataset' \n",
    "train_signals_ucihar, train_labels_ucihar, test_signals_ucihar, test_labels_ucihar = load_ucihar_data(folder_ucihar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    entropy=scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "def get_features(list_values):\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uci_har_features(dataset, labels, waveletname):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0,dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            list_coeff = pywt.wavedec(signal, waveletname)\n",
    "            for coeff in list_coeff:\n",
    "                features += get_features(coeff)\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    Y = np.array(labels)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, y_col, x_cols, ratio):\n",
    "    \"\"\" \n",
    "    This method transforms a dataframe into a train and test set, for this you need to specify:\n",
    "    1. the ratio train : test (usually 0.7)\n",
    "    2. the column with the Y_values\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(len(df)) < ratio\n",
    "    df_train = df[mask]\n",
    "    df_test = df[~mask]\n",
    "       \n",
    "    Y_train = df_train[y_col].values\n",
    "    Y_test = df_test[y_col].values\n",
    "    X_train = df_train[x_cols].values\n",
    "    X_test = df_test[x_cols].values\n",
    "    return df_train, df_test, X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 128, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_signals_ucihar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels_ucihar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ucihar, Y_train_ucihar = get_uci_har_features(train_signals_ucihar[0:1], train_labels_ucihar[0], 'rbio3.1')\n",
    "X_test_ucihar, Y_test_ucihar = get_uci_har_features(test_signals_ucihar, test_labels_ucihar, 'rbio3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 648)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ucihar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score for the UCI-HAR dataset is about: 1.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '2f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\Meu Drive\\Pós-Graduação - Mestrado UFSC - Engenharia Eletrica\\Disciplinas\\Introdução á informatica médica\\trabalhos\\Estudo de caso 01\\UCI.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/P%C3%B3s-Gradua%C3%A7%C3%A3o%20-%20Mestrado%20UFSC%20-%20Engenharia%20Eletrica/Disciplinas/Introdu%C3%A7%C3%A3o%20%C3%A1%20informatica%20m%C3%A9dica/trabalhos/Estudo%20de%20caso%2001/UCI.ipynb#ch0000027?line=3'>4</a>\u001b[0m test_score \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mscore(X_test_ucihar, Y_test_ucihar)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/P%C3%B3s-Gradua%C3%A7%C3%A3o%20-%20Mestrado%20UFSC%20-%20Engenharia%20Eletrica/Disciplinas/Introdu%C3%A7%C3%A3o%20%C3%A1%20informatica%20m%C3%A9dica/trabalhos/Estudo%20de%20caso%2001/UCI.ipynb#ch0000027?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain Score for the UCI-HAR dataset is about: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(train_score))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Meu%20Drive/P%C3%B3s-Gradua%C3%A7%C3%A3o%20-%20Mestrado%20UFSC%20-%20Engenharia%20Eletrica/Disciplinas/Introdu%C3%A7%C3%A3o%20%C3%A1%20informatica%20m%C3%A9dica/trabalhos/Estudo%20de%20caso%2001/UCI.ipynb#ch0000027?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39mTest Score for the UCI-HAR dataset is about: \u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m.2f}\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(test_score))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '2f'"
     ]
    }
   ],
   "source": [
    "cls = GradientBoostingClassifier(n_estimators=2000)\n",
    "cls.fit(X_train_ucihar, Y_train_ucihar)\n",
    "train_score = cls.score(X_train_ucihar, Y_train_ucihar)\n",
    "test_score = cls.score(X_test_ucihar, Y_test_ucihar)\n",
    "print(\"Train Score for the UCI-HAR dataset is about: {}\".format(train_score))\n",
    "print(\"Test Score for the UCI-HAR dataset is about: {.2f}\".format(test_score))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e9b47a8eab08deb4634551a4ad6f32952cd1cc3da3a48c0a5e48c34bb2d1475"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39IIM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
